{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ef1dc6",
   "metadata": {},
   "source": [
    "# TOS - AI Support Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "259aeb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from ollama import ListResponse\n",
    "from typing import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b4a6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_MODEL = ListResponse.Model\n",
    "DEFAULT_LLM = \"llama3.2:latest\"\n",
    "DEFAULT_EMBEDDING_MODEL = \"nomic-embed-text:latest\"\n",
    "BASE_OLLAMA_URL = \"http://localhost:11434/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48f8d70",
   "metadata": {},
   "source": [
    "## Check for llama3.2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5bbfb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_available_llms() -> Sequence[T_MODEL]:\n",
    "    return ollama.list().models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02d0db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_llama3_exists(models: Sequence[T_MODEL]) -> bool:\n",
    "    found = False\n",
    "    for llm in models:\n",
    "        if llm.model == DEFAULT_LLM:\n",
    "            found = True\n",
    "            break\n",
    "    return found\n",
    "\n",
    "def does_nomic_exists(models: Sequence[T_MODEL]) -> bool:\n",
    "    found = False\n",
    "    for llm in models:\n",
    "        if llm.model == DEFAULT_EMBEDDING_MODEL:\n",
    "            found = True\n",
    "            break\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2b7915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👋🏻 Found llama3.2 & nomic, good to proceed 🚀\n"
     ]
    }
   ],
   "source": [
    "llmList = list_available_llms()\n",
    "\n",
    "if does_llama3_exists(llmList) and does_nomic_exists(llmList):\n",
    "    print(\"👋🏻 Found llama3.2 & nomic, good to proceed 🚀\")\n",
    "else:\n",
    "    print(\"💣 llama3.2 or nomic, not found, install it before proceeding.... 👾\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9e47d364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a language model, so I don't have feelings or emotions like humans do, but thank you for asking! It's great to chat with you and help with any questions or topics you'd like to discuss. How about you? How's your day going?\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "def get_llm_response(query: str) -> ChatResponse:\n",
    "  return chat(model='llama3.2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': query,\n",
    "  },\n",
    "])\n",
    "\n",
    "response: ChatResponse = get_llm_response(\"Howdy, How are you?\")\n",
    "\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b69d3c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbedResponse(model='nomic-embed-text', created_at=None, done=None, done_reason=None, total_duration=16256834, load_duration=2250167, prompt_eval_count=9, prompt_eval_duration=None, eval_count=None, eval_duration=None, embeddings=[[0.027598167, 0.018781658, -0.15477675, -0.024644945, 0.035094947, 0.07115604, -0.005861922, 0.018551059, 0.0031759313, -0.05195587, 0.032453492, 0.059863314, 0.05370034, 0.051027715, 0.011734799, 0.013722353, 0.0071139983, -0.02972811, -0.009842749, -0.009175068, -0.0841475, -0.029480096, 0.0018210462, -0.031335138, 0.059098028, 0.059840374, -0.00749137, -0.00011438317, -0.013929074, -0.022525767, 0.056464385, -0.029912323, -0.025303975, -0.048517343, 0.029587407, -0.05664888, 0.03202192, -0.0027435878, -0.009240757, 0.0059798677, -0.00067473727, -0.025977822, 0.016479101, 0.0021058987, 0.02799393, -0.044759456, 0.023799997, 0.073737055, -0.03347662, -0.017991923, -0.031321146, 0.053447314, -0.004839368, -0.0912219, 0.021824727, 0.067210935, 0.02369567, -0.016063502, 0.023234231, 0.004013018, 0.063135974, 0.08434246, 0.0041208174, 0.0518183, 0.06096647, -0.043447398, -0.053342365, -0.008640058, 0.009147984, -0.015470053, 0.06917282, -0.05958942, 0.0029420324, 0.03735517, -0.028108124, -0.05196996, -0.061656814, 0.019558871, -0.005054636, 0.05001332, 0.015609899, 0.020485621, 0.02157967, 0.0103890905, 0.056352325, 0.028708048, 0.03486974, -0.016563425, -0.014181119, -0.006214065, 0.008056693, -0.027091453, 0.066491164, 0.009454638, -0.020972518, -0.00581095, -0.028764598, 0.068583764, -0.063052714, -0.030245949, -0.055378422, -0.023800148, -0.042880513, 0.03357676, 0.07068524, 0.024862846, -0.010822117, -0.008444424, -0.028307209, -0.044378497, 0.009035912, 0.032544717, -0.0040406594, 0.002021055, -0.010037009, -0.06631, 0.004339746, -0.04094243, 0.011452594, 0.09354406, 0.041558553, -0.0032523056, 0.003865079, -0.016391948, -0.009812979, 0.04789109, -0.0284971, 0.00025790333, 0.012431015, -0.04845084, -0.034407213, -0.035655703, -0.004417314, 0.012886635, 0.0049492638, 0.020570247, -0.009340588, -0.03940343, 0.006373873, 0.01956546, 0.03790036, 0.021236116, 0.045831427, -0.031357087, -0.0055365837, -0.063509434, 0.027550654, -0.00097371463, -0.011394005, -0.03365866, -0.025953837, -0.0083889505, 0.01947837, 0.030282531, 0.004996148, -0.052121498, 0.025245907, -0.009378813, 0.025797116, 0.031287257, 0.05163453, 0.022481123, -0.011766007, 0.022157863, -0.022727929, -0.030719036, 0.05241524, 0.037629962, 0.030958029, 0.035682082, -0.051232032, -0.07889538, -0.025934225, -0.043587755, -0.0024219777, 0.008778279, 0.06652548, -0.021334263, 0.008805703, -0.0380852, -0.010664847, -0.065207444, 0.014189216, 0.007478713, 0.025645815, 0.0019559907, -0.054884527, -0.038193274, -0.034316365, -0.025878048, -0.010903352, -0.024912562, -0.06566122, -0.043533053, 0.009965226, -0.022846455, 0.053356603, 0.047337964, 0.01696168, 0.017129801, -0.006667282, -0.014678252, 0.022693697, -0.010434057, 0.010862492, 0.059713554, 0.013145555, 0.04359023, -0.053521216, 0.0046954677, 0.0574187, -0.018316638, 0.0106254285, -0.0060080746, 0.056917537, 0.0041899285, -0.04552418, -0.0009894978, -0.013200341, 0.079365596, -0.021669399, 0.016972797, 0.030253394, -0.021840377, 0.0384377, 0.001724493, -0.029559825, 0.0066003236, 0.04429564, -0.016441168, 0.009771096, 0.01307167, 0.032259915, 0.033343878, 0.029187713, 0.038667623, 0.020734344, 0.05613007, -0.00914942, -0.00015667923, -0.03911867, 0.062831245, -0.07048201, 0.012399561, -0.046037246, 0.046865422, -0.021387832, -0.018187385, -0.038901586, -0.00023896096, 0.034568336, 0.004522839, 0.028815506, 0.048225727, 0.001074608, -0.07671809, -0.05911938, 0.0034515194, -0.0032205612, -0.04970455, -0.031130001, -0.038198147, 0.042011555, -0.07226402, -0.058608163, 0.054252956, -0.025080476, 0.024460822, 0.01836883, -0.07109569, 0.030779878, 0.025978735, 0.02000668, 0.012125037, 0.011245991, -0.027001055, 0.017195612, -0.02869953, -0.0052210116, 0.043691173, -0.016352896, -0.008405103, -0.032267526, -0.009526852, 0.014255376, 0.013826584, 0.023639511, 0.074414246, 0.0003913186, 0.046213094, 0.037015487, 0.010151396, 0.030833105, 0.07574189, -0.021575022, 0.03250753, 0.06303844, 0.0029476422, 0.03336121, -0.03775371, 0.012739452, 0.017893586, 0.047961924, 0.0066989223, -0.0026263623, 0.013154062, 0.0022107933, 0.018036028, 0.022262916, -0.027725091, -0.009745983, 0.055954404, -0.025411958, 0.09253428, -0.032233667, 0.054802563, 0.026204538, -0.00034962827, 0.032081965, 0.03198694, 0.018054869, -0.032561235, 0.0222213, -0.0062027564, 0.02792306, 0.036821976, -0.042013753, 0.04562272, -0.037496008, -0.04902978, -0.009740193, 0.026029095, 0.020031463, -0.018740457, -0.06979772, -0.008116008, -0.009446772, -0.05232692, -0.020395009, 0.0537948, 0.06060146, -0.08255668, -0.007290538, -0.051218648, -0.020198498, -0.01510778, -0.0056111924, -0.010634527, 0.026215993, -0.015236424, -0.016650813, 0.0060187983, 0.0069974926, -0.012081389, -0.023609135, 0.014705034, -0.026095616, 0.025050873, 0.042894334, -0.00014804071, 0.010024505, -0.048499398, -0.009608234, -0.013329607, -0.034716994, 0.035502546, 0.008542255, 0.01788772, 0.003663916, -0.012171119, -0.033083983, -0.012572271, -0.039936513, 0.051098935, 0.0125232, 0.00900101, -0.030337725, -0.058362942, 0.020503541, 0.008812145, -0.024007881, 0.032139987, 0.00097199983, 0.02097206, -0.0007544363, 0.016912887, -0.02300792, -0.053777978, -0.021970632, -0.028785056, -0.01184234, -0.057338964, -0.018647315, -0.0016845403, 0.01674808, -0.060927544, 0.05215831, -0.022913601, -0.021114446, 0.019989487, -0.025859479, -0.03559573, -0.022900812, -0.057117987, -0.0017295614, 0.028519077, -0.0074056275, -0.07170566, 0.052952632, 0.043875024, 0.02425061, 0.037244443, -0.007010065, -0.105087794, -0.00039772366, 0.0018190448, 0.020390691, 0.0032924705, 0.017329196, 0.013043141, 0.06915941, 0.0510561, 0.008814215, -0.020440748, 0.04355327, 0.016894437, 0.010397064, 0.025501257, 0.019651804, -0.050053176, 0.0024845044, -0.010386043, -0.019856468, -0.010953322, -0.056401182, 0.024672633, -0.016531369, -0.009014141, 0.01379485, 0.0797171, 0.05268438, -0.06684462, -0.027643757, -0.057478163, 0.068929456, 0.11406467, 0.014100111, -0.10339511, -0.03815946, 0.018490952, -0.017338976, -0.048100445, 0.04088692, 0.07770299, 0.086842455, -0.0056491583, -0.02695857, 0.022333315, 0.050631147, 0.0831078, 0.028680114, 0.0066120047, -0.006656688, -0.0035807837, 0.0133892065, -0.011730325, -0.0072361715, -0.0062573557, 0.0061280094, 0.030900517, -0.052947387, -0.010728653, 0.016935986, -0.032445673, -0.05692108, 0.00419688, -0.06708775, -0.003179042, 0.033507653, 0.05326551, 0.022036068, 0.03460241, -0.0145476265, -0.04279525, -0.026582377, 0.07677339, 0.009000518, 0.016220912, 0.0155421905, -0.028994702, 0.026501194, -0.033431035, 0.010185848, -0.009122611, 0.02202107, -0.016917055, 0.012562415, -0.025821403, 0.0031051938, 0.0023917127, 0.0023466346, 0.020804925, 0.023673978, 0.018014822, -0.025958346, 0.018110365, 0.03369618, -0.03708738, -0.013530623, 0.059943777, -0.023319565, -0.079305634, 0.07085514, 0.008780691, -0.0035363466, -0.04848012, -0.015413879, 0.043345764, -0.024526695, -0.012588142, 0.025934212, -0.029556323, -0.019481758, 0.009047658, -0.04022073, 0.05239077, -0.0028687818, -0.03568766, 0.021725997, 0.015979588, 0.0017981494, 0.011881743, -0.029985959, -0.033696853, 0.03167016, -0.023196954, -0.013870012, 0.046562005, -0.00014270448, 0.04182216, 0.000999466, 0.023773232, 0.02145697, -0.00039497062, -0.012173161, 0.011031886, -0.0661829, 0.01564181, 0.06454246, -0.019568915, 0.030454088, -0.04298056, 0.024502307, 0.011679417, 0.055282332, -0.025804073, 0.006205201, -0.016409334, -0.0555421, 0.005271737, 0.0054952484, 0.013071047, 0.008999891, 0.008395789, 0.0519304, -0.06520363, -0.0014002672, 0.021314867, 0.01759451, 0.00067574997, -0.0018086861, -0.018799791, -0.024477739, -0.024730278, -0.0065820413, 0.016563417, 0.009442597, 0.0059244195, -0.049558092, -0.020969976, 0.05516454, 0.0028476818, 0.054179925, -0.0023121543, -0.015033314, -0.021850191, 0.010811212, -0.05275208, 0.082408935, -0.047528222, -0.02161208, -0.012133107, -0.028084576, -0.038378697, -0.012654511, -0.050674643, -0.012381368, -0.04632275, -0.084961854, -0.0033749084, 0.021093074, -0.0344683, 0.04939967, -0.047910172, 0.015247475, 0.017875621, -0.0047495775, -0.045225825, 0.016290331, -0.013839886, 0.017320354, -0.019399764, 0.005800051, -0.008260462, 0.00348323, -0.060369037, 0.06395398, -0.0033768965, 0.03344082, -0.09453036, -0.0061026644, -0.09199633, 0.017423052, -0.052151036, 0.05462045, -0.044853065, -0.05437133, -0.052264847, 0.037368912, 0.033978567, -0.0034425317, 0.038437314, -0.011671204, -0.018683864, -0.0029166262, 0.020160263, -0.010639179, 0.030032672, 0.02788283, 0.024154581, 0.013765196, 0.047607027, 0.016395047, -0.02038613, 0.047298227, -0.0073854052, 0.05506383, -0.02171649, 0.001775865, -0.041503347, 0.060427397, 0.03403934, 0.025829235, -0.04529206, 0.028598813, -0.02252473, 0.02534169, 0.006920324, -0.021994723, -0.0969495, -0.049515434, -0.004645439, -0.10185766, 0.008514932, 0.031756196, -0.025336858, 0.013444755, -0.026217923, -0.083489835, 0.006251121, -0.03822611, 0.025478033, -0.020007577, -0.021097485, -0.0007109257, -0.011111547, 0.019922338, 0.03966191, 0.02397188, -0.0035858394, 0.043809056, 0.04277116, -0.014197345, -0.012548699, -0.014453961, -0.0098480685, -0.01964836, -0.013281668, 0.029364858, -0.11559825, 0.020572882, 0.018554205, -0.058922853, -0.07295781, 0.023027739, -0.032560755, 0.016004186, -0.030179903, 0.01902569, -0.018792193, -0.054951183, -0.0052621146, 0.01774492, 0.03962163, 0.0062665003, -0.04419873, 0.022733685, -0.021018911, -0.01014471, -0.0038320082, -0.014436258, 0.026815059, 0.016589785, 0.046759035, 0.0051746583, 0.017761683, -0.0049133236, 0.012572992, -0.028470183, 0.047655903, 0.038136434, -0.017243162, -0.029182833, -0.06837684, -0.0019068295, -0.019600764, 0.030858187, -0.06842505, -0.004549752, -0.030752843, 0.0051859906, 0.047570698, -0.012028352, 0.02359995, -0.016368704, -0.03819785, -0.027106633, 0.006620552, -0.0021036947, -0.01430352, -0.060885355, 0.011373735, 0.009480579, 0.015459742, 0.0008222839, -0.021264888, 0.013889015, 0.02475663, 0.069290176, -0.017107323, 0.02092205, 0.010690433, -0.007556436, 0.016319562, 0.02000468, 0.032268792, 0.02048818, -0.0010249349, 0.09536724, -0.002515357, 0.021483393, -0.010258576, 0.0159816, 0.033166625, -0.053866047, -0.0068975394, -0.025837896, 0.02197127]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.embed(model='nomic-embed-text', input='The sky is blue because of rayleigh scattering')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fe2423",
   "metadata": {},
   "source": [
    "## Vector DB setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6668795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.api import ClientAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a2989e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_db() -> ClientAPI | None:\n",
    "    chromadb.PersistentClient(\"../../db/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04d03738",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a12353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from chromadb import PersistentClient\n",
    "from tqdm import tqdm\n",
    "import ollama\n",
    "\n",
    "# ---- Config ----\n",
    "ZIP_PATH = 'docs_dump.zip'\n",
    "EXTRACT_DIR = 'extracted_docs'\n",
    "CHROMA_DB_PATH = '../../db/'\n",
    "COLLECTION_NAME = 'help_docs'\n",
    "CHUNK_SIZE = 500  # words per chunk\n",
    "CHUNK_OVERLAP = 100\n",
    "SKIP_EXTENSIONS = {\n",
    "    '.css', '.js', '.png', '.jpg', '.jpeg', '.gif', '.svg', '.ico',\n",
    "    '.woff', '.woff2', '.ttf', '.eot', '.mp4', '.mp3', '.pdf'\n",
    "}\n",
    "\n",
    "\n",
    "# ---- Utilities ----\n",
    "def extract_zip(zip_path, extract_dir):\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "\n",
    "\n",
    "def is_valid_file(file):\n",
    "    ext = os.path.splitext(file)[-1].lower()\n",
    "    return ext in ['.html', '.htm'] and ext not in SKIP_EXTENSIONS\n",
    "\n",
    "\n",
    "def html_to_text(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='latin-1') as f:\n",
    "                content = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to decode {filepath}: {e}\")\n",
    "            return None\n",
    "\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    return soup.get_text(separator=' ').strip()\n",
    "\n",
    "\n",
    "\n",
    "def chunk_text(text, chunk_size=500, overlap=100):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(' '.join(words[start:end]))\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def embed_chunks(chunks):\n",
    "    return [\n",
    "        ollama.embeddings(model='nomic-embed-text', prompt=chunk)['embedding']\n",
    "        for chunk in tqdm(chunks, desc='Embedding chunks')\n",
    "    ]\n",
    "\n",
    "\n",
    "def save_to_chromadb(chunks, embeddings, collection_name, db_path):\n",
    "    client = PersistentClient(path=db_path)\n",
    "    if collection_name in [c.name for c in client.list_collections()]:\n",
    "        collection = client.get_collection(collection_name)\n",
    "    else:\n",
    "        collection = client.create_collection(collection_name)\n",
    "\n",
    "    for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "        collection.add(\n",
    "            ids=[f'doc-{i}'],\n",
    "            documents=[chunk],\n",
    "            embeddings=[embedding]\n",
    "        )\n",
    "\n",
    "\n",
    "# ---- Main ----\n",
    "def process_zip(zip_path):\n",
    "    extract_zip(zip_path, EXTRACT_DIR)\n",
    "\n",
    "    for root, _, files in os.walk(EXTRACT_DIR):\n",
    "        for file in files:\n",
    "            if is_valid_file(file):\n",
    "                filepath = os.path.join(root, file)\n",
    "                text = html_to_text(filepath)\n",
    "                if text:\n",
    "                    chunks = chunk_text(text, CHUNK_SIZE, CHUNK_OVERLAP)\n",
    "                    embeddings = embed_chunks(chunks)\n",
    "                    save_to_chromadb(chunks, embeddings, COLLECTION_NAME, CHROMA_DB_PATH)\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipping undecodable file: {file}\")\n",
    "            else:\n",
    "                print(f\"⏭️ Skipping non-HTML file: {file}\")\n",
    "\n",
    "    print(\"✅ All embeddings saved to ChromaDB!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8c271de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding chunks: 100%|██████████| 1/1 [00:00<00:00, 108.55it/s]\n",
      "Embedding chunks: 100%|██████████| 1/1 [00:00<00:00, 111.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Skipping non-HTML file: script.js\n",
      "⏭️ Skipping non-HTML file: style.css\n",
      "⏭️ Skipping non-HTML file: ._docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding chunks: 100%|██████████| 1/1 [00:00<00:00, 115.06it/s]\n",
      "Embedding chunks: 100%|██████████| 1/1 [00:00<00:00, 81.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Skipping non-HTML file: ._style.css\n",
      "⏭️ Skipping non-HTML file: ._script.js\n",
      "✅ All embeddings saved to ChromaDB!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_zip(\"../../sampledata/docs.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dee75ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_client():\n",
    "    client = PersistentClient(path=CHROMA_DB_PATH)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2e5265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is TOS?\"\n",
    "collection = get_db_client().get_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1fa77fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_related_chunks(query, collection, top_k=3):\n",
    "    query_embedding = ollama.embeddings(\n",
    "        model=\"nomic-embed-text\",\n",
    "        prompt=query\n",
    "    )[\"embedding\"]\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "\n",
    "    return list(zip(\n",
    "        results[\"documents\"][0],\n",
    "        results.get(\"distances\", [[]])[0]\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e14b74a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TOS Welcome to TOS TOS stands for Technical Operation Services',\n",
       "  155.60223388671875)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_chunks = find_related_chunks(query, collection)\n",
    "related_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ae87b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_augmented_prompt(query, related_chunks):\n",
    "    context = \"\\n\".join([chunk[0] for chunk in related_chunks])\n",
    "    prompt = f\"\"\"You are a helpful assistant. Use the context below to answer the user's question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "72742abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_prompt = build_augmented_prompt(query, related_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d234df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(augmented_prompt) -> ChatResponse:\n",
    "  return chat(model='llama3.2', messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant who can answer questions about space but only answers questions that are directly related to the sources/documents given.\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": augmented_prompt}\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e414a06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not able to find any information on what TOS specifically refers to in this context, as you haven't provided any additional information or sources related to Technical Operation Services. Can you please provide more context or clarify which source the term \"TOS\" comes from? I'll do my best to help with your question.\n"
     ]
    }
   ],
   "source": [
    "response: ChatResponse = generate_response(ag_prompt)\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "683038f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('TOS Welcome to TOS TOS stands for Technical Operation Services', 563.8402099609375)]\n",
      "Unfortunately, I don't have any information about the author of TOS in my knowledge database as it was not specified. The provided context does not mention any sources or documents that would allow me to determine the author. Can you provide more context or clarify which document or source you are referring to?\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is the author\"\n",
    "related_chunks = find_related_chunks(query, collection)\n",
    "print(related_chunks)\n",
    "ag_prompt = build_augmented_prompt(query, related_chunks)\n",
    "response: ChatResponse = generate_response(ag_prompt)\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6993ef27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = get_db_client()\n",
    "collection = client.get_collection(name=COLLECTION_NAME)\n",
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3644ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
